import React, { useRef, useState, useEffect } from "react";
import { Mic, MicOff } from "lucide-react";
import { useSpeechSynthesis } from "react-speech-kit";

export default function App() {
  const canvasRef = useRef(null);
  const [listening, setListening] = useState(false);
  const [permissionError, setPermissionError] = useState(false);
  const [consoleLog, setConsoleLog] = useState("");
  const [responseText, setResponseText] = useState("");
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const { speak, voices } = useSpeechSynthesis();
  const [isSpeaking, setIsSpeaking] = useState(false);

  // const BACKEND_URL = "https://katcon.registration.envisionsit.com/upload_audio"; // üîÅ change to your backend API
const BACKEND_URL = "http://172.16.3.154:8000/upload_audio"; // üîÅ change to your backend API
  // --- üéµ Visualizer ---
  const drawVisualizer = () => {
    const canvas = canvasRef.current;
    if (!canvas) return;
    const ctx = canvas.getContext("2d");
    const width = canvas.width;
    const height = canvas.height;
    let animationFrameId;

    const draw = () => {
      if (!isSpeaking) {
        ctx.clearRect(0, 0, width, height);
        animationFrameId = requestAnimationFrame(draw);
        return;
      }

      ctx.clearRect(0, 0, width, height);
      const dots = 24;
      const cx = width / 2;
      const cy = height / 2;
      const baseRadius = Math.min(width, height) * 0.18;

      for (let i = 0; i < dots; i++) {
        const angle = (i / dots) * Math.PI * 2;
        const pulse = Math.sin(Date.now() / 200 + i * 0.4) * 0.25 + 0.75;
        const r = baseRadius * (1 + pulse * 0.4);
        const x = cx + Math.cos(angle) * r;
        const y = cy + Math.sin(angle) * r;
        const hue = (i * (360 / dots) + Date.now() / 20) % 360;
        const size = 6 + pulse * 10;

        ctx.beginPath();
        ctx.arc(x, y, size, 0, Math.PI * 2);
        ctx.fillStyle = `hsl(${hue}, 90%, 60%)`;
        ctx.shadowBlur = 30;
        ctx.shadowColor = `hsl(${hue}, 90%, 60%)`;
        ctx.fill();
      }

      animationFrameId = requestAnimationFrame(draw);
    };

    draw();
    return () => cancelAnimationFrame(animationFrameId);
  };

  // --- üéôÔ∏è Welcome Message ---
  const starting = () => {
    if (!isSpeaking && !listening) {
      const voice = voices.find((v) => v.lang.startsWith("en")) || voices[0];
      setIsSpeaking(true);
      speak({
        text: "Welcome to Envision Junior. If you need any assistance, please tap the microphone button and ask your question.",
        voice,
        rate: 1,
        pitch: 1,
        onend: () => setIsSpeaking(false),
      });
    }
  };



  useEffect(() => {
 
    if (isSpeaking) drawVisualizer();
  }, [isSpeaking]);

async function getMedia(constraints) {
  let stream = null;

  try {
    stream = await navigator.mediaDevices.getUserMedia(constraints);
    /* use the stream */
  } catch (err) {
    /* handle the error */
  }
}
  const requestPermission = async () => {
    try {
      console.log("Requesting microphone permission...");
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        console.error("getUserMedia not supported");
        throw new Error("getUserMedia not supported in this browser.");
      }
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setPermissionError(false);
      stream.getTracks().forEach((track) => track.stop());
      return true;
    } catch (err) {
      console.error("‚ùå Microphone permission denied:", err);
      setPermissionError(true);
      return false;
    }
  };

  useEffect(() => {
    requestPermission();
  }, []);

  // --- üéß Start Recording ---
  const startMic = async () => {
    const permissionGranted = await requestPermission();
    if (!permissionGranted) return;

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setListening(true);

      const mediaRecorder = new MediaRecorder(stream);
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) audioChunksRef.current.push(event.data);
      };

      mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunksRef.current, { type: "audio/webm" });
        const formData = new FormData();
        formData.append("file", blob, "recording.webm");

        console.log("üéôÔ∏è Sending audio to backend...");

        try {
          const res = await fetch(BACKEND_URL, { method: "POST", body: formData });
          const data = await res.json();

          console.log(" Backend response received.");
          console.log(data);

          if (data.response) {
            console.log(data.response);

            const voice = voices.find((v) => v.lang.startsWith("en")) || voices[0];
            setIsSpeaking(true);
            speak({
              text: data.response,
              voice,
              rate: 1,
              pitch: 1,
              onend: () => setIsSpeaking(false),
            });
          }
        } catch (err) {
          console.error("‚ùå Upload failed:", err);
          console.log("Sorry, I couldn‚Äôt process your question.");
        }
      };

      mediaRecorder.start();
      mediaRecorderRef.current = mediaRecorder;
      setConsoleLog("üéß Recording started...");
    } catch (err) {
      console.error("‚ùå Error starting microphone:", err);
      setConsoleLog("‚ùå Error starting microphone");
    }
  };

  // --- ‚èπÔ∏è Stop Recording ---
  const stopMic = () => {
    setListening(false);
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
      setConsoleLog("‚èπÔ∏è Recording stopped");
    }
  };

  useEffect(() => {
    requestPermission();
  }, []);

  return (
    <div style={{ background: "#000", color: "#fff", minHeight: "100vh" }}>
      <canvas
        ref={canvasRef}
        width={window.innerWidth}
        height={window.innerHeight}
        style={{
          position: "absolute",
          top: 0,
          left: 0,
          zIndex: 1,
          background: "#050608",
        }}
      />

      {/* üé§ Mic Button */}
      <div
        style={{
          position: "relative",
          zIndex: 10,
          height: "100vh",
          display: "flex",
          flexDirection: "column",
          alignItems: "center",
          justifyContent: "center",
        }}
      >
        <button
          onClick={listening ? stopMic : startMic}
          style={{
            background: listening ? "#ff4b4b" : "#0077ff",
            border: "none",
            borderRadius: "50%",
            width: "90px",
            height: "90px",
            display: "flex",
            justifyContent: "center",
            alignItems: "center",
            boxShadow: "0 0 25px rgba(255,255,255,0.2)",
            cursor: "pointer",
            transition: "all 0.3s ease",
          }}
        >
          {listening ? <MicOff size={40} color="white" /> : <Mic size={40} color="white" />}
        </button>

      

        {/* ‚ö†Ô∏è Permission Error */}
        {permissionError && (
          <p
            style={{
              color: "#ff5555",
              textAlign: "center",
              marginTop: "20px",
            }}
          >
            ‚ö†Ô∏è Please allow microphone access in your browser or device settings.
          </p>
        )}

        {/* üßæ Console Log */}
        {/* <small style={{ color: "#aaa", marginTop: "10px" }}>{consoleLog}</small> */}
      </div>
    </div>
  );
}
